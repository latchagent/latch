---
title: Latch - Security Guardrails for AI Agents
sidebarTitle: Introduction
description: Open-source guard proxy for MCP servers. Stop your AI agent before it does something you'll regret.
---

## Introduction

AI agents are incredibly powerful. They can read your files, execute shell commands, send emails, query databases, and make API calls on your behalf.

But what happens when your agent decides to:
- Search for passwords in your home directory?
- Delete files it thinks are "temporary"?
- Send confidential data to the wrong recipient?
- Run a shell command that nukes your database?

**You need a human in the loop. You need Latch.**

<div style={{ position: 'relative', paddingBottom: '56.25%', height: 0 }}>
  <iframe 
    src="https://www.loom.com/embed/8afb303827984c4e97453c5ed04608b3" 
    frameBorder="0" 
    allowFullScreen 
    style={{ position: 'absolute', top: 0, left: 0, width: '100%', height: '100%' }}
  />
</div>

## What is Latch?

Latch is an open-source guard proxy that sits between your AI agent and its tools. Every tool call passes through Latch, which enforces your security policies:

| Action | What Happens |
|--------|--------------|
| ‚úÖ Safe operations | Pass through automatically (reads, internal writes) |
| ‚ö†Ô∏è Risky operations | Require your approval (shell commands, external sends) |
| üõë Forbidden operations | Blocked entirely (payments, destructive actions) |
| ü§ñ LLM policies | Natural language conditions evaluated in real-time |

## Quick Example

```bash
# Without Latch
Agent: "Search for API keys in ~/"
‚Üí üí• Agent finds and potentially leaks your secrets

# With Latch
Agent: "Search for API keys in ~/"  
‚Üí üõë Blocked by policy: "Searches targeting sensitive files"
‚Üí You see it in the audit log
‚Üí Crisis averted
```

## Key Features

<CardGroup cols={2}>
  <Card title="Policy Engine" icon="shield">
    Rules based on tool name, action class, domain, and recipient. Most-specific rule wins.
  </Card>
  <Card title="LLM-Evaluated Policies" icon="sparkles">
    Write policy conditions in plain English. An LLM evaluates each tool call against them.
  </Card>
  <Card title="Approval Workflow" icon="check">
    Risky actions pause for your approval. Single-use tokens or time-limited leases.
  </Card>
  <Card title="Telegram Notifications" icon="bell">
    Get notified on your phone. Approve or deny with one tap.
  </Card>
  <Card title="Audit Log" icon="scroll">
    Full history of every tool call, decision, and redacted arguments.
  </Card>
  <Card title="Self-Hosted" icon="server">
    Run on your infrastructure. Your data never leaves your control.
  </Card>
</CardGroup>

## Works With

Latch works with any MCP (Model Context Protocol) compatible client and server:

**Clients:**
- Claude Desktop
- Cursor
- Any MCP-compatible agent

**Servers (examples):**
- Filesystem access
- GitHub operations
- Database queries
- Shell commands
- Email/Slack
- Any custom MCP server

## See It In Action

### The Dashboard

Create workspaces, manage upstreams, and monitor everything in one place.

![Latch dashboard](/docs/assets/dashboard.png)

### Policy Rules

Define what's allowed, what's blocked, and what needs approval.

![Latch policies](/docs/assets/policies.png)

### Audit Log

Every request logged with the decision and redacted arguments.

![Latch audit log](/docs/assets/audit-logs.png)

## Get Started in 5 Minutes

<CardGroup cols={2}>
  <Card title="Quickstart" icon="rocket" href="./quickstart">
    Run Latch locally with Docker and wrap your first MCP server.
  </Card>
  <Card title="Claude Desktop Setup" icon="message-bot" href="./claude-desktop">
    Step-by-step guide to integrate Latch with Claude Desktop.
  </Card>
</CardGroup>

## Open Source

Latch is fully open source under the MIT license. 

- [GitHub Repository](https://github.com/latchhq/latch)
- [Report Issues](https://github.com/latchhq/latch/issues)
- [Contributing Guide](https://github.com/latchhq/latch/blob/main/CONTRIBUTING.md)

---

*Built for developers who want AI agents they can actually trust.*
